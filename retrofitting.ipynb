{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# python3\n",
    "#\n",
    "import argparse\n",
    "import gzip\n",
    "import math\n",
    "import numpy\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isNumber = re.compile(r'\\d+.*')\n",
    "def norm_word(word):\n",
    "    if isNumber.search(word.lower()):\n",
    "        return '---num---'\n",
    "    elif re.sub(r'\\W+', '', word) == '':\n",
    "        return '---punc---'\n",
    "    else:\n",
    "        return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Read all the word vectors and normalize them\"\"\"\n",
    "def read_word_vecs(filename):\n",
    "    wordVectors = {}\n",
    "    # ファイル読み込み\n",
    "    if filename.endswith('.gz'): \n",
    "        fileObject = gzip.open(filename, 'r')\n",
    "    else: \n",
    "        fileObject = codecs.open(filename, \"r\", \"utf-8\", 'ignore')\n",
    "        \n",
    "    for line in fileObject:\n",
    "        # line = line.strip().lower()\n",
    "        line = line.strip()\n",
    "        word = line.split()[0]\n",
    "        wordVectors[word] = numpy.zeros(len(line.split())-1, dtype=float)\n",
    "        for index, vecVal in enumerate(line.split()[1:]):\n",
    "            wordVectors[word][index] = float(vecVal)\n",
    "        \"\"\"normalize weight vector\"\"\"\n",
    "        wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-6)\n",
    "\n",
    "    sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "    return wordVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Write word vectors to file\"\"\"\n",
    "def print_word_vecs(wordVectors, outFileName):\n",
    "    sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
    "    outFile = open(outFileName, 'w')  \n",
    "    for word, values in wordVectors.items():\n",
    "        outFile.write(word+' ')\n",
    "        for val in wordVectors[word]:\n",
    "            outFile.write('%.4f' %(val)+' ')\n",
    "        outFile.write('\\n')      \n",
    "    outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Read the PPDB.etc word relations as a dictionary\"\"\"\n",
    "def read_lexicon(filename):\n",
    "    lexicon = {}\n",
    "    fileObject = open(filename, 'r')\n",
    "    for line in fileObject:\n",
    "        words = line.lower().strip().split()\n",
    "        lexicon[norm_word(words[0])] = [norm_word(word) for word in words[1:]]\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Retrofit word vectors to a lexicon\"\"\"\n",
    "def retrofit(wordVecs, lexicon, numIters):\n",
    "    # Input word vecs\n",
    "    newWordVecs = deepcopy(wordVecs)\n",
    "    # Input word vecsの単語リスト\n",
    "    wvVocab = set(newWordVecs.keys())\n",
    "    # wvVocabとlexiconの共通単語\n",
    "    loopVocab = wvVocab.intersection(set(lexicon.keys()))\n",
    "\n",
    "    for _ in range(numIters): #10回程度\n",
    "        # loop through every node also in ontology (else just use data estimate)\n",
    "        for word in loopVocab:\n",
    "            # lexicon wordの近傍単語とwvVocabの共通単語とその個数\n",
    "            wordNeighbours = set(lexicon[word]).intersection(wvVocab)\n",
    "            numNeighbours = len(wordNeighbours)\n",
    "            # no neighbours -> pass - use data estimate\n",
    "            if numNeighbours == 0:\n",
    "                continue\n",
    "            \"\"\"分散表現の更新手続き\"\"\"\n",
    "            # the weight of the data estimate if the number of neighbours\n",
    "            newVec = numNeighbours * wordVecs[word]\n",
    "            # loop over neighbours and add to new vector (currently with weight 1)\n",
    "            for ppWord in wordNeighbours:\n",
    "                newVec += newWordVecs[ppWord]\n",
    "            newWordVecs[word] = newVec/(2*numNeighbours)\n",
    "    return newWordVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(v1, v2):\n",
    "    n1 = np.linalg.norm(v1) # v1のノルム\n",
    "    n2 = np.linalg.norm(v2) # v2のノルム\n",
    "    return np.dot(v1, v2) / (n1*n2) # 内積 / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 変数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input word vecs -> original\n",
    "input_arg = './word2vec/vectors.model'\n",
    "# Lexicon file name\n",
    "lexicon_arg = './lexicons/wordnet-jpn.txt'\n",
    "# Lexicon file name（keyとvalueに共通の単語を含まない）\n",
    "lexicon_arg = './result.txt'\n",
    "# Num iterations\n",
    "numiter_arg = 10\n",
    "# Output word vecs -> retrofitting\n",
    "output_arg = './out_vec.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numIter = int(numiter_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outFileName = output_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lexicon = read_lexicon(lexicon_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ./word2vec/vectors.model \n"
     ]
    }
   ],
   "source": [
    "wordVecs = read_word_vecs(input_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_vec = retrofit(wordVecs, lexicon, numIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrofittingした分散表現を保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing down the vectors in ./out_vec.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Enrich the word vectors using ppdb and print the enriched vectors\"\"\"\n",
    "print_word_vecs(new_vec, outFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec\n",
    "vecs_wordVecs = wordVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrofitting\n",
    "vecs_new_vec = new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordNeighbours : {'高齢', '年中', '老年', '歳', '年紀', '一年', '年歯', '年間', '老齢', '老いらく', '年令', '年度', '老い', '年齢', '馬齢', '年頃', '年次', '齢', '歳次', '年代'}\n",
      "numNeighbours : 20\n",
      "分母 : 40\n"
     ]
    }
   ],
   "source": [
    "word = '年'\n",
    "newWordVecs = deepcopy(wordVecs)\n",
    "wvVocab = set(wordVecs.keys())\n",
    "wordNeighbours = set(lexicon[word]).intersection(wvVocab)\n",
    "print('wordNeighbours : {}'.format(wordNeighbours))\n",
    "numNeighbours = len(wordNeighbours)\n",
    "print('numNeighbours : {}'.format(numNeighbours))\n",
    "newVec = numNeighbours * wordVecs[word]\n",
    "for ppWord in wordNeighbours:\n",
    "    newVec += newWordVecs[ppWord]\n",
    "print('分母 : {}'.format(2*numNeighbours))\n",
    "newWordVecs[word] = newVec/(2*numNeighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●wordsim算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def checkSim(v1, v2):\n",
    "    if v1 not in lexicon:\n",
    "        print(\"v1 not found error in dict\")\n",
    "    else:\n",
    "        wordNeighbours_1 = set(lexicon[v1]).intersection(set(wordVecs.keys()))\n",
    "        print('wordNeighbours_v1 : {}'.format(wordNeighbours_1))\n",
    "        print('numNeighbours_v1 : {}'.format(len(wordNeighbours_1)))\n",
    "    if v2 not in lexicon:\n",
    "        print(\"v2 not found error in dict\")\n",
    "    else:\n",
    "        wordNeighbours_2 = set(lexicon[v2]).intersection(set(wordVecs.keys()))\n",
    "        print('wordNeighbours_v2 : {}'.format(wordNeighbours_2))\n",
    "        print('numNeighbours_v2 : {}'.format(len(wordNeighbours_2)))\n",
    "    print(\" \")\n",
    "    print('wordNeighboursの共通単語 : {}'.format(set(wordNeighbours_1).intersection(set(wordNeighbours_2))))\n",
    "    print(\" \")\n",
    "\n",
    "    \"\"\"v1とv2のword2vecとretrofittingにおける類似度\"\"\"\n",
    "    try:\n",
    "        print(\"word2vec : {}\".format(similarity(vecs_wordVecs[v1], vecs_wordVecs[v2])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    try:\n",
    "        print(\"retrofitting : {}\".format(similarity(vecs_new_vec[v1], vecs_new_vec[v2])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    print(\" \")\n",
    "    \"\"\"同一単語におけるword2vecとretrofittingの類似度\"\"\"\n",
    "    try:\n",
    "        print(\"v1 : {}\".format(similarity(vecs_wordVecs[v1], vecs_new_vec[v1])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    try:\n",
    "        print(\"v2 : {}\".format(similarity(vecs_wordVecs[v2], vecs_new_vec[v2])))\n",
    "    except:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordNeighbours_v1 : {'虎', 'タイガー'}\n",
      "numNeighbours_v1 : 2\n",
      "wordNeighbours_v2 : {'ねんねこ', '猫', 'にゃんにゃん'}\n",
      "numNeighbours_v2 : 3\n",
      " \n",
      "wordNeighboursの共通単語 : set()\n",
      " \n",
      "word2vec : 0.5214821607397867\n",
      "retrofitting : 0.545527993271341\n",
      " \n",
      "v1 : 0.9460903473614132\n",
      "v2 : 0.9137972129149805\n"
     ]
    }
   ],
   "source": [
    "v1 = 'トラ'\n",
    "v2 = 'ネコ'\n",
    "checkSim(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_1_dict = deepcopy(vecs_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"明日の方針\"\"\"\n",
    "# トラと虎とタイガーがwordvecのkeyとwordnetのvalueにどの程度含まれているか\n",
    "\n",
    "# 類似度から特徴を捉える\n",
    "## （やや）上がりやすい単語の組み合わせの特徴\n",
    "## （やや）下がりやすい単語の組み合わせの特報\n",
    "## 類似度が下がっていない組み合わせはないか？（現在，見つかっていない）\n",
    "\n",
    "# wordnetに含まれているかどうか\n",
    "## wordnetに含まれているもの同士（？）\n",
    "## wordnetに片方だけ含まれているもの同士（？）\n",
    "## wordnetに両方含まれているもの同士（ベクトルは変化しない）\n",
    "\n",
    "# ベクトル内の比較\n",
    "## word2vecとretrofittingでどう変わったか（次元）\n",
    "## 変化のパターンを見つけたり，，，\n",
    "\n",
    "# イテレーション回数\n",
    "## イテレーション回数が少ない，周辺単語同士を考慮したベクトル表現になっているはず\n",
    "## イテレーション回数が多いと，遠い単語同士を考慮したベクトル表現になっているはず"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    ex_1 = 2*vecs_wordVecs['トラ'] + ex_1_dict['虎'] + ex_1_dict['タイガー']\n",
    "    ex_1_dict['トラ'] = ex_1/4\n",
    "    \n",
    "    ex_1 = 2*vecs_wordVecs['虎'] + ex_1_dict['トラ'] + ex_1_dict['タイガー']\n",
    "    ex_1_dict['虎'] = ex_1/4\n",
    "    \n",
    "    ex_1 = 2*vecs_wordVecs['タイガー'] + ex_1_dict['トラ'] + ex_1_dict['虎']\n",
    "    ex_1_dict['タイガー'] = ex_1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    ex_1 = 3*vecs_wordVecs['ネコ'] + ex_1_dict['ねんねこ'] + ex_1_dict['猫'] + ex_1_dict['にゃんにゃん']\n",
    "    ex_1_dict['ネコ'] = ex_1/6\n",
    "    \n",
    "    ex_1 = 9*vecs_wordVecs['ねんねこ'] + ex_1_dict['ネコ'] + ex_1_dict['御寝'] + ex_1_dict['睡眠'] + ex_1_dict['にゃんにゃん'] + ex_1_dict['眠り'] + ex_1_dict['ねね'] + ex_1_dict['就眠'] + ex_1_dict['スリープ'] + ex_1_dict['猫']\n",
    "    ex_1_dict['ねんねこ'] = ex_1/18\n",
    "    \n",
    "    ex_1 = 3*vecs_wordVecs['猫'] + ex_1_dict['ネコ'] + ex_1_dict['ねんねこ'] + ex_1_dict['にゃんにゃん']\n",
    "    ex_1_dict['猫'] = ex_1/6\n",
    "    \n",
    "    ex_1 = 3*vecs_wordVecs['にゃんにゃん'] + ex_1_dict['ネコ'] + ex_1_dict['ねんねこ'] + ex_1_dict['猫']\n",
    "    ex_1_dict['にゃんにゃん'] = ex_1/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5214821607397867"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(vecs_wordVecs['トラ'], vecs_wordVecs['ネコ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5214821350254598"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(ex_1_dict['トラ'], ex_1_dict['ネコ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●アナロジー算出\n",
    "### v1+v2-v3, v4の類似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkAnalogy(vecs, w_vec):  \n",
    "    negative = False # Falseなら似た単語を候補で上げる\n",
    "    threshold = 0.3 # -1なら閾値固定\n",
    "\n",
    "    # 閾値の設定\n",
    "    border_positive = threshold if threshold > 0 else 0.9\n",
    "    border_negative = threshold if threshold > 0 else 0.2\n",
    "    print('{} < thd < {}'.format(border_negative, border_positive))\n",
    "\n",
    "    # 候補数の設定\n",
    "    max_candidates = 20\n",
    "    candidates = {}\n",
    "\n",
    "    for w in vecs:\n",
    "        try:\n",
    "            if w_vec.shape != vecs[w].shape:\n",
    "                raise Exception(\"size not match\")\n",
    "            s = similarity(w_vec, vecs[w])\n",
    "        except Exception as ex:\n",
    "            print(w + \" is not valid word.\")\n",
    "            continue\n",
    "\n",
    "        if negative and s <= border_negative:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_negative -= 0.05\n",
    "        elif not negative and s >= border_positive:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_positive += 0.05\n",
    "\n",
    "        if len(candidates) > max_candidates:\n",
    "            break\n",
    "\n",
    "    # 類義語算出\n",
    "    sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "    for c in sorted_candidates:\n",
    "        print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec : 0.3855693677632116\n",
      "retrofitting : 0.455162528951861\n"
     ]
    }
   ],
   "source": [
    "v1 = '兄'\n",
    "v2 = '姉'\n",
    "v3 = '祖父'\n",
    "v4 = '祖母'\n",
    "\n",
    "if v1 not in lexicon:\n",
    "    print(\"v1 not found error in dict\")\n",
    "if v2 not in lexicon:\n",
    "    print(\"v2 not found error in dict\")\n",
    "if v3 not in lexicon:\n",
    "    print(\"v3 not found error in dict\")\n",
    "if v4 not in lexicon:\n",
    "    print(\"v4 not found error in dict\")\n",
    "\n",
    "try:\n",
    "    print('word2vec : {}'.format(similarity(vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3], vecs_wordVecs[v4])))\n",
    "except:\n",
    "    print('error')\n",
    "\n",
    "try:\n",
    "    print('retrofitting : {}'.format(similarity(vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3], vecs_new_vec[v4])))\n",
    "except:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1+v2-v3の上位10単語"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 < thd < 0.3\n",
      "754069 is not valid word.\n",
      "姉, 0.8433279735101462\n",
      "兄, 0.7622779357580127\n",
      "妹, 0.7553375375315672\n",
      "弟, 0.7011033258786433\n",
      "双子, 0.5541898022518956\n",
      "夫, 0.5241162973051148\n",
      "年上, 0.5228285283574702\n",
      "次女, 0.49053484292919564\n",
      "兄弟, 0.4801388417438813\n",
      "叔父, 0.48004084731816965\n",
      "甥, 0.4646477248521072\n",
      "母, 0.4618720699656536\n",
      "長女, 0.4522498603989746\n",
      "娘。, 0.4484254297338895\n",
      "彼女, 0.41874909255787995\n",
      "妻, 0.4180556386599047\n",
      "息子, 0.38730153006548584\n",
      "父, 0.3860297212008132\n",
      "結婚, 0.3574390676533354\n",
      "男, 0.35215392646403093\n",
      "2人, 0.32434570907744076\n"
     ]
    }
   ],
   "source": [
    "checkAnalogy(vecs_wordVecs, vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 < thd < 0.3\n",
      "754069 is not valid word.\n",
      "弟, 0.7363773440569735\n",
      "彼女, 0.5633848313623006\n",
      "母, 0.5338945818801998\n",
      "息子, 0.5296488931378206\n",
      "妻, 0.5185961348730093\n",
      "娘。, 0.5039797586656193\n",
      "男, 0.48125902457162945\n",
      "女性, 0.46642095554235585\n",
      "子供, 0.4618583755895169\n",
      "彼, 0.46079785092814735\n",
      "父, 0.45328663166247235\n",
      "結婚, 0.44679014492847346\n",
      "子, 0.4105021820226309\n",
      "2人, 0.4091101937240521\n",
      "自分, 0.3918472036563103\n",
      "思う, 0.37224827169148844\n",
      "出演, 0.3608708120523299\n",
      "メンバー, 0.3513207187726019\n",
      "後, 0.33321416563642\n",
      "優勝, 0.3050190720842435\n",
      "活動, 0.3010650673095817\n"
     ]
    }
   ],
   "source": [
    "checkAnalogy(vecs_new_vec, vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # ベクトルの設定\n",
    "# w_vec = vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3]\n",
    "# vecs = vecs_wordVecs\n",
    "# for w in vecs:\n",
    "#     try:\n",
    "#         if w_vec.shape != vecs[w].shape:\n",
    "#             raise Exception(\"size not match\")\n",
    "#         s = similarity(w_vec, vecs[w])\n",
    "#     except Exception as ex:\n",
    "#         print(w + \" is not valid word.\")\n",
    "#         continue\n",
    "\n",
    "#     if negative and s <= border_negative:\n",
    "#         candidates[w] = s\n",
    "#         if len(candidates) % 5 == 0:\n",
    "#             border_negative -= 0.05\n",
    "#     elif not negative and s >= border_positive:\n",
    "#         candidates[w] = s\n",
    "#         if len(candidates) % 5 == 0:\n",
    "#             border_positive += 0.05\n",
    "\n",
    "#     if len(candidates) > max_candidates:\n",
    "#         break\n",
    "\n",
    "# # 類義語算出\n",
    "# sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "# for c in sorted_candidates:\n",
    "#     print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # ベクトルの設定\n",
    "# w_vec = vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3]\n",
    "# vecs = vecs_new_vec\n",
    "# for w in vecs:\n",
    "#     try:\n",
    "#         if w_vec.shape != vecs[w].shape:\n",
    "#             raise Exception(\"size not match\")\n",
    "#         s = similarity(w_vec, vecs[w])\n",
    "#     except Exception as ex:\n",
    "#         print(w + \" is not valid word.\")\n",
    "#         continue\n",
    "\n",
    "#     if negative and s <= border_negative:\n",
    "#         candidates[w] = s\n",
    "#         if len(candidates) % 5 == 0:\n",
    "#             border_negative -= 0.05\n",
    "#     elif not negative and s >= border_positive:\n",
    "#         candidates[w] = s\n",
    "#         if len(candidates) % 5 == 0:\n",
    "#             border_positive += 0.05\n",
    "\n",
    "#     if len(candidates) > max_candidates:\n",
    "#         break\n",
    "\n",
    "# # 類義語算出\n",
    "# sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "# for c in sorted_candidates:\n",
    "#     print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ●wordに対する上位10単語"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = '彼女'\n",
    "# path = \"./fastText/model.vec\"\n",
    "negative = False # Falseなら似た単語を候補で上げる\n",
    "threshold = 0.6 # -1なら閾値固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkSim_by_word(vecs, word):\n",
    "    # 閾値の設定\n",
    "    border_positive = threshold if threshold > 0 else 0.8\n",
    "    border_negative = threshold if threshold > 0 else 0.3\n",
    "\n",
    "    # 候補数の設定\n",
    "    max_candidates = 20\n",
    "    candidates = {}\n",
    "    \n",
    "    # wordの設定確認\n",
    "    if not word:\n",
    "        raise Exception(\"word is missing\")\n",
    "\n",
    "    # wordがモデルにない場合，\n",
    "    if word not in vecs:\n",
    "        raise Exception(\"Sorry, this word is not registered in model.\")\n",
    "\n",
    "    # ベクトルの設定\n",
    "    w_vec = vecs[word]\n",
    "\n",
    "    # ナレッジグラフにあるかどうかの確認\n",
    "    lexicon = read_lexicon(lexicon_arg)\n",
    "    if word not in lexicon:\n",
    "    #     raise Exception(\"not found error in dict\")\n",
    "        print(\"not found error in dict\")\n",
    "    \n",
    "    for w in vecs:\n",
    "        try:\n",
    "            if w_vec.shape != vecs[w].shape:\n",
    "                raise Exception(\"size not match\")\n",
    "            s = similarity(w_vec, vecs[w])\n",
    "        except Exception as ex:\n",
    "            print(w + \" is not valid word.\")\n",
    "            continue\n",
    "\n",
    "        if negative and s <= border_negative:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_negative -= 0.05\n",
    "        elif not negative and s >= border_positive:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_positive += 0.05\n",
    "\n",
    "        if len(candidates) > max_candidates:\n",
    "            break\n",
    "    \n",
    "    # 類義語算出\n",
    "    sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "    for c in sorted_candidates:\n",
    "        print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754069 is not valid word.\n",
      "彼女, 1.0\n",
      "彼, 0.7881711200018091\n",
      "彼女自身, 0.7454731084176603\n",
      "彼女たち, 0.7367573651943607\n",
      "彼女ら, 0.6977034431164688\n",
      "自分, 0.670073388263443\n",
      "ルービツ, 0.654221608969978\n",
      "フィリピエヴナ, 0.654103015163623\n",
      "彼ら, 0.640895342831867\n",
      "私, 0.6133480216235981\n"
     ]
    }
   ],
   "source": [
    "checkSim_by_word(vecs_wordVecs, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754069 is not valid word.\n",
      "彼女, 1.0\n",
      "ガールフレンド, 0.8702002492417416\n",
      "彼, 0.8646146491713587\n",
      "恋人, 0.8645802592529555\n",
      "女友達, 0.8311695203495161\n",
      "ボーイフレンド, 0.8124718679947734\n",
      "彼氏, 0.7801455673281661\n",
      "愛人, 0.7650726037527209\n",
      "姉, 0.7288931909201077\n",
      "母親, 0.7185616060061439\n",
      "彼女たち, 0.7185170521135521\n",
      "少女, 0.7085028367621702\n",
      "夫, 0.7052696026212519\n",
      "友人, 0.6895894359368071\n",
      "妻, 0.6895129146007162\n",
      "女, 0.6675841616411355\n",
      "女性, 0.6668317039751089\n",
      "自分, 0.6601343505245548\n",
      "結婚, 0.6003957244867856\n"
     ]
    }
   ],
   "source": [
    "checkSim_by_word(vecs_new_vec, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # wordの設定確認\n",
    "# if not word:\n",
    "#     raise Exception(\"word is missing\")\n",
    "    \n",
    "# # wordがモデルにない場合，\n",
    "# if word not in vecs:\n",
    "#     raise Exception(\"Sorry, this word is not registered in model.\")\n",
    "\n",
    "# # ベクトルの設定\n",
    "# w_vec = vecs[word]\n",
    "\n",
    "# # ナレッジグラフにあるかどうかの確認\n",
    "# lexicon = read_lexicon(lexicon_arg)\n",
    "# if word not in lexicon:\n",
    "# #     raise Exception(\"not found error in dict\")\n",
    "#     print(\"not found error in dict\")\n",
    "\n",
    "# # 閾値の設定\n",
    "# border_positive = threshold if threshold > 0 else 0.8\n",
    "# border_negative = threshold if threshold > 0 else 0.3\n",
    "\n",
    "# # 候補数の設定\n",
    "# max_candidates = 20\n",
    "# candidates = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for w in vecs:\n",
    "#     try:\n",
    "#         if w_vec.shape != vecs[w].shape:\n",
    "#             raise Exception(\"size not match\")\n",
    "#         s = similarity(w_vec, vecs[w])\n",
    "#     except Exception as ex:\n",
    "#         print(w + \" is not valid word.\")\n",
    "#         continue\n",
    "\n",
    "#     if negative and s <= border_negative:\n",
    "#         candidates[w] = s\n",
    "#         if len(candidates) % 5 == 0:\n",
    "#             border_negative -= 0.05\n",
    "#     elif not negative and s >= border_positive:\n",
    "#         candidates[w] = s\n",
    "#         if len(candidates) % 5 == 0:\n",
    "#             border_positive += 0.05\n",
    "\n",
    "#     if len(candidates) > max_candidates:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # 類義語算出\n",
    "# sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "# for c in sorted_candidates:\n",
    "#     print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
